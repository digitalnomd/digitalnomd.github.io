---
title: "Automation Bias"
date: 2024-11-04
---

Recently I learned of a concept called automation bias and deskilling via automation. They seem to go hand-in-hand because as we rely on automated systems we use our skills less.

To further explain, automation bias describes how we are likely to implicitly trust something that is generated programmatically and the deskilling describes where we rely on a technology so much that we forget how it works or how we ever lived without it.

Which is to say that that part of our brains has atrophied in some way and we've ceded our abilities of being able to do the thing that we used to do to a machine that does it for us.

This shows up all over the place. For example, most people have forgotten how a car works now that we have automatic transmissions. Before, when cars had newly been created, the average driver knew how to perform basic maintenance, and often did when the car broke down on the side of the road. Albeit they were much simpler then. But still, we've lost that skill by and large as a society as cars became more and more automated.

Generally, we welcome these engineering improvements because they make our lives easier, but it's a slippery slope as complex systems have bugs and giving up our skillsets make us less likely to spot errors.

Moreover, automated systems are likely not error free and in the case of modern AI systems, they're not tapping into some objective truth. They're depend on how system was trained.

Take neural networks as an example. The way they work at a high-level is by showing a network many inputs and outputs and having it learn to predict those outputs through making guesses and then adjusting weights for their layers based on how fair off they were from the correct output.

It's easy to assume that this process produces results that are objectively true, but consider that these outputs where often times generated through a person labeling them who could've easily make a mistake.

Not to mention there are things like overfitting that could throw off a model.

The point is that if we get too comfortable with using these systems, it leads to a situation where we can no longer tell when they're giving us bogus results. And as these systems to get more ingrained in our society, and are responsbile for more important functions, that's a scary thought.

What will our society look like when automation makes it easier to appear clever and as a result we are diskilled in our most important ability of all -- the ability to think clearly.

How does automation deskill our ability to think?

AI is now capable of generated writing that we can use in school, business, and our social lives. As Paul Graham put it in so many words, writing clearly is thinking clearly. And without us having to develop the skill of writing because we can just use AI then most people will never get good at thinking.
